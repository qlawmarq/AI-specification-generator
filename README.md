# AI Specification Generator

LangChain-based CLI tool for generating specification documents from large codebases using semantic analysis and progressive prompting.

## üåü Features

- **üîç Semantic Code Analysis**: Uses Tree-sitter for AST-based parsing of multiple programming languages
- **ü§ñ LangChain Integration**: Progressive prompting strategy (analysis ‚Üí generation) with GPT-4
- **üìù Japanese Documentation**: Generates IT industry standard specification documents in Japanese
- **üíæ Large Codebase Support**: Memory-efficient streaming processing for 4GB+ repositories
- **‚ö° Incremental Updates**: Git-based semantic diff detection for specification updates
- **üîß CLI Interface**: Rich command-line interface with progress indicators and error handling
- **üåê Multi-Provider LLM**: Support for OpenAI, Azure OpenAI, and Google Gemini with rate limiting
- **üìä Memory Management**: Real-time monitoring with configurable limits and batch processing

## üèóÔ∏è Architecture

```
CLI Layer (Typer + Rich)
    ‚Üì
Core Processing (AsyncGenerator + Streaming)
    ‚Üì
Semantic Analysis (Tree-sitter + AST)
    ‚Üì
LLM Generation (LangChain + Progressive Prompting)
    ‚Üì
Japanese Templates (IT Industry Standards)
    ‚Üì
Output Generation (Markdown + Metadata)
```

## üöÄ Quick Start

### Prerequisites

- Python 3.9+
- One of the following LLM providers:
  - OpenAI API key (for specification generation)
  - Azure OpenAI access
  - Google Gemini API key
- Git (for incremental updates)

#### Setting up Gemini API

1. **Get Gemini API Key:**

   - Visit [Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key)
   - Create a new project or select an existing one
   - Generate an API key

2. **Configure Gemini:**

   ```bash
   # Set environment variable
   export GEMINI_API_KEY="your-gemini-api-key"
   export LLM_PROVIDER="gemini"
   export LLM_MODEL="gemini-2.0-flash"  # Optional: defaults to gemini-2.0-flash
   ```

3. **Supported Gemini Models:**
   - `gemini-2.0-flash` (default, fast and efficient)
   - `gemini-2.5-pro-preview-03-25` (advanced capabilities)
   - `gemini-2.5-flash-preview-04-17` (optimized for speed)

### Installation

1. **Clone the repository:**

```bash
git clone https://github.com/your-username/AI-specification-generator.git
cd AI-specification-generator
```

2. **Install dependencies:**

```bash
pip install -e .
```

3. **Install Tree-sitter parsers:**

```bash
spec-generator install-parsers
```

4. **Set up environment variables:**

```bash
cp .env.example .env
# Edit .env and add your OpenAI API key
export OPENAI_API_KEY="your-api-key-here"
```

### Basic Usage

**Generate specification for entire repository:**

```bash
spec-generator generate /path/to/your/repo \
  --output ./specifications \
  --project-name "„Éû„Ç§„Ç∑„Çπ„ÉÜ„É†" \
  --languages python javascript
```

**Generate specification for single file:**

```bash
spec-generator generate-single src/main.py \
  --output single-spec.md
```

**Update existing specification:**

```bash
spec-generator update /path/to/repo \
  --existing-spec specifications/current-spec.md \
  --base-commit HEAD~1 \
  --target-commit HEAD
```

**View configuration:**

```bash
spec-generator config-info
```

## üìã Commands

### `generate`

Generate complete specification documentation from a codebase.

```bash
spec-generator generate [REPO_PATH] [OPTIONS]
```

**Options:**

- `--output, -o`: Output directory (default: `./specifications`)
- `--project-name, -p`: Project name in Japanese (default: `„Ç∑„Çπ„ÉÜ„É†`)
- `--languages, -l`: Programming languages to process
- `--semantic-chunking`: Use semantic chunking (requires OpenAI API)
- `--max-files`: Maximum number of files to process
- `--estimate-only`: Only estimate processing time

### `update`

Update existing specification based on code changes.

```bash
spec-generator update [REPO_PATH] [OPTIONS]
```

**Options:**

- `--output, -o`: Output directory (default: `./spec-updates`)
- `--base-commit`: Base commit for comparison (default: `HEAD~1`)
- `--target-commit`: Target commit (default: `HEAD`)
- `--existing-spec`: Path to existing specification

### `generate-single`

Generate specification for a single file.

```bash
spec-generator generate-single [FILE_PATH] [OPTIONS]
```

### `install-parsers`

Install Tree-sitter language parsers.

```bash
spec-generator install-parsers [OPTIONS]
```

**Options:**

- `--languages, -l`: Specific languages to install
- `--force`: Force reinstallation

## ‚öôÔ∏è Configuration

Configuration is managed entirely through environment variables. Copy `.env.example` to `.env` and configure your settings.

### Environment Variables

```bash
# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key

# Azure OpenAI Configuration (alternative to OpenAI)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-azure-key
AZURE_OPENAI_VERSION=2024-02-01

# Gemini API Configuration (alternative to OpenAI)
GEMINI_API_KEY=your-gemini-api-key

# LLM Provider Selection
LLM_PROVIDER=openai  # Options: openai, azure, gemini
LLM_MODEL=gpt-4  # Optional: override default model

# Processing Configuration
CHUNK_SIZE=4000
CHUNK_OVERLAP=200
MAX_MEMORY_MB=1024
PARALLEL_PROCESSES=4
SUPPORTED_LANGUAGES=python,javascript,typescript,java,cpp,c

# Output Configuration
OUTPUT_FORMAT=japanese_detailed_design
DOCUMENT_TITLE=„Ç∑„Çπ„ÉÜ„É†‰ªïÊßòÊõ∏

# Performance Settings
REQUEST_TIMEOUT=30
MAX_RETRIES=3
RETRY_DELAY=1
RATE_LIMIT_RPM=200
BATCH_SIZE=10
```

### Configuration Setup

1. **Copy the example configuration:**

   ```bash
   cp .env.example .env
   ```

2. **Edit the .env file with your API keys and preferences:**

   ```bash
   # Required: Set your LLM provider
   OPENAI_API_KEY=sk-your-actual-api-key
   LLM_PROVIDER=openai

   # Optional: Adjust processing settings
   MAX_MEMORY_MB=2048
   PARALLEL_PROCESSES=8
   ```

3. **Load the configuration:**
   ```bash
   source .env  # or use direnv for automatic loading
   ```

## üìñ Output Examples

### Generated Specification Structure

```markdown
# „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂêç Ë©≥Á¥∞Ë®≠Ë®àÊõ∏

**ÊñáÊõ∏„Éê„Éº„Ç∏„Éß„É≥**: 1.0
**‰ΩúÊàêÊó•**: 2025 Âπ¥ 07 Êúà 15 Êó•
**ÊúÄÁµÇÊõ¥Êñ∞Êó•**: 2025 Âπ¥ 07 Êúà 15 Êó•

---

## ÁõÆÊ¨°

1. [Ê¶ÇË¶Å](#Ê¶ÇË¶Å)
2. [„Ç∑„Çπ„ÉÜ„É†ÊßãÊàê](#„Ç∑„Çπ„ÉÜ„É†ÊßãÊàê)
3. [Ë©≥Á¥∞Ë®≠Ë®à](#Ë©≥Á¥∞Ë®≠Ë®à)
4. [ÈùûÊ©üËÉΩË¶Å‰ª∂](#ÈùûÊ©üËÉΩË¶Å‰ª∂)
5. [ÈÅãÁî®Ë®≠Ë®à](#ÈÅãÁî®Ë®≠Ë®à)
6. [‰ªòÈå≤](#‰ªòÈå≤)

---

## 1. Ê¶ÇË¶Å

### 1.1 ÊñáÊõ∏„ÅÆÁõÆÁöÑ

„Ç∑„Çπ„ÉÜ„É†„ÅÆË©≥Á¥∞Ë®≠Ë®à„ÇíË®òËø∞„Åô„Çã

### 1.2 „Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å

[Generated system overview in Japanese]

### 1.3 ÂØæË±°Ë™≠ËÄÖ

ÈñãÁô∫„ÉÅ„Éº„É†„ÄÅÈÅãÁî®„ÉÅ„Éº„É†

## 2. „Ç∑„Çπ„ÉÜ„É†ÊßãÊàê

### 2.1 ÂÖ®‰Ωì„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£

[Generated architecture description]

### 2.2 ‰∏ªË¶Å„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà

[Component descriptions]

### 2.3 ÊäÄË°ì„Çπ„Çø„ÉÉ„ÇØ

[Technology stack details]

## 3. Ë©≥Á¥∞Ë®≠Ë®à

### 3.1 „É¢„Ç∏„É•„Éº„É´Ë®≠Ë®à

[Module design details]

### 3.2 „Éá„Éº„ÇøË®≠Ë®à

[Data structure definitions]

### 3.3 Âá¶ÁêÜË®≠Ë®à

[Processing flow descriptions]
```

## üß™ Development

### Running Tests

```bash
# Install development dependencies
pip install -e ".[dev]"

# Run all tests
pytest tests/ -v

# Run specific test categories
pytest tests/test_models.py -v
pytest tests/test_integration.py -k "not slow" -v

# Run with coverage
pytest tests/ --cov=spec_generator --cov-report=html
```

### Code Quality

```bash
# Format code
black src/ tests/

# Lint code
ruff check src/ tests/

# Type checking
mypy src/
```

### Project Structure

```
src/spec_generator/
‚îú‚îÄ‚îÄ __init__.py                 # Package initialization
‚îú‚îÄ‚îÄ cli.py                      # Main CLI interface
‚îú‚îÄ‚îÄ config.py                   # Configuration management
‚îú‚îÄ‚îÄ models.py                   # Pydantic data models
‚îú‚îÄ‚îÄ core/                       # Core processing modules
‚îÇ   ‚îú‚îÄ‚îÄ processor.py            # Large codebase processor
‚îÇ   ‚îú‚îÄ‚îÄ generator.py            # Specification generator
‚îÇ   ‚îú‚îÄ‚îÄ diff_detector.py        # Semantic diff detection
‚îÇ   ‚îî‚îÄ‚îÄ updater.py              # Specification updater
‚îú‚îÄ‚îÄ parsers/                    # Code parsing modules
‚îÇ   ‚îú‚îÄ‚îÄ tree_sitter_parser.py   # Tree-sitter integration
‚îÇ   ‚îî‚îÄ‚îÄ ast_analyzer.py         # AST analysis
‚îú‚îÄ‚îÄ templates/                  # Document templates
‚îÇ   ‚îú‚îÄ‚îÄ japanese_spec.py        # Japanese spec templates
‚îÇ   ‚îî‚îÄ‚îÄ prompts.py              # LangChain prompts
‚îî‚îÄ‚îÄ utils/                      # Utility modules
    ‚îú‚îÄ‚îÄ file_utils.py           # File operations
    ‚îú‚îÄ‚îÄ git_utils.py            # Git operations
    ‚îú‚îÄ‚îÄ simple_memory.py        # Simple memory tracking
    ‚îî‚îÄ‚îÄ common.py               # Common utilities
```

## üîß Advanced Usage

### Custom Configuration

Create custom environment configurations for specific projects:

```bash
# Create project-specific .env file
cp .env.example my-project/.env

# Edit for project-specific settings
echo "CHUNK_SIZE=2000" >> my-project/.env
echo "MAX_MEMORY_MB=2048" >> my-project/.env
echo "SUPPORTED_LANGUAGES=python,typescript" >> my-project/.env

# Use with the project
cd my-project
source .env
spec-generator generate ./src
```

### Processing Large Repositories

For repositories larger than 1GB, use these optimizations:

```bash
# Use estimation mode first
spec-generator generate /large/repo --estimate-only

# Process with limits (set via environment)
export MAX_MEMORY_MB=4096
export PARALLEL_PROCESSES=2
spec-generator generate /large/repo \
  --max-files 1000 \
  --semantic-chunking
```

### Incremental Updates

Set up automated specification updates:

```bash
#!/bin/bash
# update-specs.sh
spec-generator update /path/to/repo \
  --existing-spec docs/current-spec.md \
  --output docs/updated-specs/ \
  --base-commit $(git rev-parse HEAD~1) \
  --target-commit $(git rev-parse HEAD)
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 style guidelines
- Add tests for new features
- Update documentation for API changes
- Use type hints throughout
- Write meaningful commit messages

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain) for LLM integration framework
- [Tree-sitter](https://tree-sitter.github.io/) for syntax tree parsing
- [Typer](https://typer.tiangolo.com/) for CLI framework
- [Rich](https://github.com/Textualize/rich) for beautiful terminal output
- [Pydantic](https://pydantic-docs.helpmanual.io/) for data validation

## üìû Support

- **Documentation**: [Project Wiki](https://github.com/your-username/AI-specification-generator/wiki)
- **Issues**: [GitHub Issues](https://github.com/your-username/AI-specification-generator/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-username/AI-specification-generator/discussions)

---

**Built with ‚ù§Ô∏è for the Japanese IT community**
